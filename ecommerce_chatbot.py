# -*- coding: utf-8 -*-
"""Ecommerce Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IibGrWJW_pYklRU8rPPzo8sq3ZOaqTR_
"""

!pip install streamlit
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import re
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st

# Load the data from the CSV file
data = pd.read_csv('/content/drive/MyDrive/data.csv')

# Display the first few rows of the dataset to understand its structure
data.head()

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Preprocess the data
data.fillna('', inplace=True)

# Define a function for basic NLP preprocessing
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Tokenize
    words = word_tokenize(text)
    # Remove stop words
    words = [word for word in words if word.isalnum()]
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]
    # Lemmatize
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    return words

# Function to preprocess text without external downloads
def preprocess_text_basic(text):
    # Convert to lowercase
    text = text.lower()
    # Remove non-alphanumeric characters
    text = re.sub(r'[^a-z0-9\s]', '', text)
    # Split into words
    words = text.split()
    # Remove common stop words
    stop_words = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',
                  'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',
                  'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',
                  'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',
                  'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',
                  'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off',
                  'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',
                  'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',
                  'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'}
    words = [word for word in words if word not in stop_words]
    return words

# Refine the search function to filter by relevant categories
def search_products_refined(query, data, top_n=5):
    processed_query = preprocess_text_basic(query)
    results = []

    # Filter by relevant categories for a cream for dry skin
    relevant_categories = ["Beauty & Personal Care", "Health & Household"]
    data_filtered = data[data['Category'].str.contains('|'.join(relevant_categories), case=False, na=False)]

    # Search for products that match the query in the filtered data
    for _, row in data_filtered.iterrows():
        product_name = row['Product Name'].lower()
        match_count = sum(word in product_name for word in processed_query)
        if match_count > 0:
            results.append((match_count, row))

    # Sort results by match count and return top_n products
    results.sort(key=lambda x: x[0], reverse=True)
    top_results = [result[1] for result in results[:top_n]]
    return top_results

# Design conversational responses
def offer_products(products):
    response = "Here are some products that might tickle your fancy:\n"
    for i, product in enumerate(products, 1):
        response += f"{i}. {product['Product Name']} - {product['Selling Price']}\n"
        response += f"   [Product URL]({product['Product Url']})\n"
        if product['Product Description']:
            response += f"   Description: {product['Product Description']}\n"
        response += "\n"
    response += "Do you need more information on any of these products?"
    return response

# Simulate chatbot interaction
def chatbot_interaction(query):
    products = search_products_refined(query, data)
    if products:
        return offer_products(products)
    else:
        return "I'm sorry, I couldn't find any products that match your request. Could you please provide more details?"

# Example customer query
customer_query = "I'm looking for a cream for dry skin."

# Get chatbot response
chatbot_response = chatbot_interaction(customer_query)
chatbot_response

# Load a pre-trained NLP model
nlp = spacy.load('en_core_web_sm')

def get_intent(user_input):
    doc = nlp(user_input)
    # Simple intent detection based on keywords
    if 'cream' in user_input and 'dry skin' in user_input:
        return 'find_product', 'cream for dry skin'
    # Add more intents as needed
    return 'unknown', ''

# Sample product descriptions
product_descriptions = data['description']

# Vectorize the product descriptions
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(product_descriptions)

def find_closest_products(query, top_n=5):
    query_vec = vectorizer.transform([query])
    similarity = cosine_similarity(query_vec, tfidf_matrix).flatten()
    top_indices = similarity.argsort()[-top_n:][::-1]
    return data.iloc[top_indices]

def chatbot_response(user_input):
    intent, query = get_intent(user_input)

    if intent == 'find_product':
        products = find_closest_products(query)
        response = "Here are some products you might like:\n"
        for idx, row in products.iterrows():
            response += f"{row['name']}: {row['description']}\n"
        response += "Need more details about any of these products?"
    else:
        response = "I'm not sure what you're looking for. Could you please clarify?"

    # Add some wit
    response += "\n(And don't worry, I'm here to help you find the perfect product!)"

    return response


# User Interface with Streamlit
st.title('E-commerce Chatbot')

user_input = st.text_input('You:', '')

if user_input:
    response = chatbot_response(user_input)
    st.text_area('Bot:', value=response, height=200, max_chars=None, key=None)